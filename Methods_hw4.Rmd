---
title: "Methods_hw4"
output: github_document
author: "Yishan Wang"
date: "2018-11-12"
---

# Problem 2

```{r include = FALSE}
library(tidyverse)
```

```{r}
heartdisease_data = read_csv("./data/HeartDisease.csv")
```

### a)

#### Description of the Data Set

The main outcome is `totalcost` of patients diagnosed with heart disease. The main predictor is `ERvisits`, which is number of emergency room visits. Other important covariates are `age`, `gender`, `complications` and `duration`. `interventions`, `drugs` and `comorbidities` are potential covariates.

#### Descriptive Statistics for all Variables of Interest

##### Descriptive statistics for continous variables of interest:

```{r}
heartdisease_data %>%
  select(totalcost, ERvisits, age, complications, duration) %>%
  summary()
```

##### Descriptive statistics for categorical variable of interest:

```{r}
table(factor(heartdisease_data$gender, levels = c(0, 1), labels = c('Male', 'Female'))) %>%
  addmargins()
```

### b)

#### Plot the distribution for variable `totalcost`:

```{r}
hist(heartdisease_data$totalcost, main = "Total Cost Distribution", xlab = "Total Cost ($)", col.main = "red", col.lab = "blue")
```

#### Use log transformation:

```{r}
hist(log(heartdisease_data$totalcost), main = "Total Cost Distribution", xlab = "Total Cost ($)", col.main = "red", col.lab = "blue")
```

### c)

#### Create a new variable called `comp_bin` by dichotomizing `complications`: 0 if no complications, and 1 otherwise.

```{r}
new_heartdisease_data = heartdisease_data %>%
  mutate(comp_bin = as.factor(ifelse(complications == 0, 0, 1))) %>%
  mutate(gender = as.factor(gender))
```

### d)

#### Fit a simple linear regression between the original `totalcost` and predictor `ERvisits`.

```{r}
ggplot(heartdisease_data, aes(x = ERvisits, y = totalcost)) +
  geom_point() +
  geom_smooth(method = 'lm',formula = y~x)

reg_original_slr = lm(totalcost ~ ERvisits, heartdisease_data)
summary(reg_original_slr)
```

##### Comments on significance and interpretation of the slope: 


#### Fit a simple linear regression between the transformed `totalcost` and predictor `ERvisits`.

```{r}
trans_heartdisease_data = heartdisease_data %>%
  filter(totalcost != 0) %>%
  mutate(trans_totalcost = log(totalcost)) 

ggplot(trans_heartdisease_data, aes(x = ERvisits, y = trans_totalcost)) +
  geom_point() +
  geom_smooth(method = 'lm', formula = y~x)

reg_trans_slr = lm(trans_totalcost ~ ERvisits, trans_heartdisease_data)
summary(reg_trans_slr)
```

##### Comments on significance and interpretation of the slope: 

### c)

#### Fit a multiple linear regression with `comp_bin` and `ERvisits` as predictors.

```{r}
reg_original_mlr = lm(totalcost ~ ERvisits + comp_bin, new_heartdisease_data)
summary(reg_original_mlr)
```

##### I)

##### Test if `comp_bin` is an effect modifier of the relationship between `totalcost` and `ERvisits`. 

```{r}
reg_interaction = lm(totalcost ~ ERvisits + comp_bin + ERvisits * comp_bin, new_heartdisease_data)
summary(reg_interaction)
```

##### Comment

##### II)

##### Test if `comp_bin` is a confounder of the relationship between `totalcost` and `ERvisits`. 

```{r}

```

##### Comment

##### III)

### f)

##### I)

#####  Use the model in part e) and add additional covariates and fit MLR.

```{r}
full_model = lm(totalcost ~ ERvisits + comp_bin + age + gender + duration, new_heartdisease_data)
summary(full_model)
```

##### Comment

##### II)

```{r}
anova(reg_original_slr, full_model)
```

# Problem 3

```{r}
patsatisfaction_data = readxl::read_excel("./data/PatSatisfaction.xlsx") %>%
  janitor::clean_names()
```

### a)

#### Create a correlation matrix

```{r}
Hmisc::rcorr(as.matrix(patsatisfaction_data))
pairs(patsatisfaction_data)
```

##### Initial Findings

* Satisfaction and age have the strong negative association. Satisfication has the moderately strong negative association with both severity and anxiety. 

* Anxiety and severity have the moderately strong positive association, we might want to check **collinearity** later. 

* Severity and age have the moderately strong positive association, which is the same as the association between anxiety and age.

### b)

##### Fit a multiple regression model and test whether there is a regression relation and test whether there is a regression relation.

```{r}
reg_mlr = lm(safisfaction ~ age + severity + anxiety, patsatisfaction_data)
summary(reg_mlr)
```

##### State the hypotheses, decision rule and conclusion.

Ho: beta_age = beta_severity = beta_anxiety = 0

Ha: at least one beta is not 0

If the p-value is less than 0.05, we reject Ho and conclude that at least one beta is not 0 and there is a regression relation. If not, we do not reject Ho and conclude that beta_age = beta_severity = beta_anxiety = 0 and there is not a regression relation.

Since p-value is far less than 0.05, we reject Ho and conclude that at least one beta is not 0 and there is a regression relation.

### c)

```{r}
confint(reg_mlr, level = 0.95) %>%
  knitr::kable(digits = 1)
```

* The 95% CI for beta_0 is (121.9, 195.1).

* The 95% CI for beta_age is (-1.6, -0.7).

* The 95% CI for beta_severity is (-1.4, 0.6).

* The 95% CI for beta_anxiety is (-27.8, 0.9). 

##### Interpret the coefficient and 95% CI associated with `severity`.

* The coefficient of `severity`: satisfaction will decrease by 0.442 units on average if severity increases by 1 unit adjusting age and anxiety constant.

* We are 95% confident that satisfaction will differ between -1.4 units and 0.6 units on average if severity increases by 1 unit adjusting age and anxiety constant.

### d)

##### Obtain an interval estimate for a new patientâ€™s satisfaction when Age = 35, Severity = 42, Anxiety = 2.1. 

```{r}
input_data = data.frame(age = 35, severity = 42, anxiety = 2.1)
predict(reg_mlr, input_data, interval = "predict")
```

##### Interpret

We are 95% confident that the next new satisfaction observation with age = 35, severity = 42, and anxiety = 2.1 is between 50 and 93. 

### e)

##### Test whether `anxiety` can be dropped from the regression model, given the other two covariates are retained.

```{r}
reg_mlr_sub = lm(safisfaction ~ age + severity, patsatisfaction_data)
summary(reg_mlr_sub)

anova(reg_mlr_sub, reg_mlr)
```

##### State the hypotheses, decision rule and conclusion.

Ho: beta_anxiety = 0

Ha: beta_anxiety != 0

If the p-value is less than 0.05, we reject Ho and conclude that beta_anxiety is not 0 and we can't drop the variable anxiety from the regression model. If not, we do not reject Ho and conclude that beta_anxiety is 0 and we can drop the variable anxiety from the regression model.

Since p-value is greater than 0.05, we don't reject Ho and conclude that beta_anxiety is 0 and we can drop the variable anxiety from the regression model.
