---
title: "Methods_hw4"
output: github_document
author: "Yishan Wang"
date: "2018-11-12"
---

# Problem 2

```{r include = FALSE}
library(tidyverse)
```

```{r}
heartdisease_data = read_csv("./data/HeartDisease.csv")
```

### a)

#### Description of the Data Set

The main outcome is `totalcost` of patients diagnosed with heart disease. The main predictor is `ERvisits`, which is number of emergency room visits. Other important covariates are `age`, `gender`, `complications` and `duration`. `interventions`, `drugs` and `comorbidities` are potential covariates.

#### Descriptive Statistics for all Variables of Interest

##### Descriptive statistics for continous variables of interest:

```{r}
heartdisease_data %>%
  select(totalcost, ERvisits, age, complications, duration) %>%
  summary() %>%
  knitr::kable(digits = 1)
```

##### Descriptive statistics for categorical variable of interest:

```{r}
table(factor(heartdisease_data$gender, levels = c(1, 0), labels = c('Male', 'Female'))) %>%
  addmargins() %>%
  knitr::kable(digits = 1)
```

### b)

#### Plot the distribution for variable `totalcost`:

```{r}
hist(heartdisease_data$totalcost, main = "Total Cost Distribution", xlab = "Total Cost ($)", col.main = "red", col.lab = "blue")
```

#### Use log transformation:

```{r}
hist(log(heartdisease_data$totalcost), main = "Total Cost Distribution", xlab = "Total Cost ($)", col.main = "red", col.lab = "blue")
```

### c)

#### Create a new variable called `comp_bin` by dichotomizing `complications`: 0 if no complications, and 1 otherwise.

```{r}
new_heartdisease_data = heartdisease_data %>%
  mutate(comp_bin = as.factor(ifelse(complications == 0, 0, 1))) %>%
  mutate(gender = as.factor(gender))
```

### d)

#### Fit a simple linear regression between the original `totalcost` and predictor `ERvisits`.

Ho: beta_ERvisits = 0

Ha: beta_ERvisits != 0

Model: totolcost = beta_0 + beta_ERvisits * ERvisits

```{r}
ggplot(heartdisease_data, aes(x = ERvisits, y = totalcost)) +
  geom_point() +
  geom_smooth(method = 'lm', formula = y~x)

reg_original_slr = lm(totalcost ~ ERvisits, heartdisease_data)
summary(reg_original_slr)
```

##### Comments on significance and interpretation of the slope: 

* From the p-value of the F test, we can conclude that the test is significant and there is a linear relationship between `totalcost` and `ERvisits`, and `ERvisits` is a significant predictor of `totalcost`. But only 14% of variation of `totalcost` around its mean can be explained by the model.

* We expect the total cost will increase $955.44 on average if the number of emergency room (ER) visits increase 1 more time.

#### Fit a simple linear regression between the transformed `totalcost` and predictor `ERvisits`.

Ho: beta_ERvisits = 0

Ha: beta_ERvisits != 0

Model: trans_totolcost = beta_0 + beta_ERvisits * ERvisits

```{r}
trans_heartdisease_data = heartdisease_data %>%
  filter(totalcost != 0) %>%
  mutate(trans_totalcost = log(totalcost)) %>%
  mutate(comp_bin = as.factor(ifelse(complications == 0, 0, 1))) %>%
  mutate(gender = as.factor(gender))

ggplot(trans_heartdisease_data, aes(x = ERvisits, y = trans_totalcost)) +
  geom_point() +
  geom_smooth(method = 'lm', formula = y~x)

reg_trans_slr = lm(trans_totalcost ~ ERvisits, trans_heartdisease_data)
summary(reg_trans_slr)
```

##### Comments on significance and interpretation of the slope: 

* From the p-value of the F test, we can conclude that the test is significant and there is a linear relationship between the transformed `totalcost` and `ERvisits`, and `ERvisits` is a significant predictor of the transformed `totalcost`. But only 10% of variation of the transformed `totalcost` around its mean can be explained by the model.

* We expect the total cost will increase exp(0.23 + 5.54) = $321 on average if the number of emergency room (ER) visits increase 1 more time.

### e)

#### Fit a multiple linear regression with `comp_bin` and `ERvisits` as predictors.

Ho: beta_ERvisits = beta_comp_bin = 0

Ha: at lease one beta is not 0

Model: trans_totolcost = beta_0 + beta_ERvisits * ERvisits + beta_comp_bin * comp_bin

```{r}
reg_trans_mlr = lm(trans_totalcost ~ ERvisits + comp_bin, trans_heartdisease_data)
summary(reg_trans_mlr)
```

##### I)

##### Test if `comp_bin` is an effect modifier of the relationship between `totalcost` and `ERvisits`. 

Ho: beta_ERvisits = beta_comp_bin = beta_ERvisits&comp_bin = 0

Ha: at lease one beta is not 0

Model: trans_totolcost = beta_0 + beta_ERvisits * ERvisits + beta_comp_bin * comp_bin + beta_ERvisits&comp_bin * ERvisits&comp_bin

```{r}
reg_interaction = lm(trans_totalcost ~ ERvisits + comp_bin + ERvisits * comp_bin, trans_heartdisease_data)
summary(reg_interaction)
```

##### Comment

Since the p-value of 'ERvisits:comp_bin1' is greater than 0.05, `comp_bin` is not an effect modifier of the relationship between `totalcost` and `ERvisits`

##### II)

##### Test if `comp_bin` is a confounder of the relationship between `totalcost` and `ERvisits`. 

|beta_ERvisits_slr - beta_ERvisits_mlr| / beta_ERvisits_slr = |0.23 - 0.20| / 0.23 = 0.13, which is greater than 10%, so `comp_bin` is a confounder of the relationship between `totalcost` and `ERvisits`.

##### III)

##### Decide if `comp_bin` should be included along with ‘ERvisits.

Ho: beta_comp_bin = 0

Ha: beta_comp_bin != 0

```{r}
anova(reg_trans_slr, reg_trans_mlr)
```

##### Reason 

`comp_bin` should be included along with ‘ERvisits because the p-value of the F test is less than 0.05 and it indicates that beta_camp_bin is not equal to 0 and `comp_bin` is significant to predict `totalcost`.

### f)

##### I)

#####  Use the model in part e) and add additional covariates and fit MLR.

Ho: beta_ERvisits = beta_comp_bin = beta_age = beta_gender = beta_duration = 0

Ha: at lease one beta is not 0

Model: trans_totolcost = beta_0 + beta_ERvisits * ERvisits + beta_comp_bin * comp_bin + beta_age * age + beta_gender * gender + beta_duration * duration

```{r}
full_model = lm(trans_totalcost ~ ERvisits + comp_bin + age + gender + duration, trans_heartdisease_data)
summary(full_model)
```

##### Comment

* From the p-value of the F test, we can conclude that the test is significant and there is a linear relationship between the transformed `totalcost` and `ERvisits`, `comp_bin`, `age`, `gender`, `duration`.

* `ERvisits`, `comp_bin`, `age`, and `duration` are significant predictors of the transformed `totalcost`. But `gender` is not significant predictors of the transformed `totalcost`.

* 27% of the variation of the transformed `totalcost` around its mean can be explained by the multiple linear regression model.

##### II)

Ho: beta_comp_bin = beta_age = beta_gender = beta_duration = 0

Ha: at lease one beta is not 0

```{r}
anova(reg_trans_slr, full_model)
```

I should use MLR than SLR because:

* More variation of the transformed `totalcost` around its mean can be explained by the multiple linear regression model.

* Since the p-value of F test is less than 0.05, there is at least one beta not equal to 0 among beta_camp_bin, beta_age, beta_gender, and beta_duration.

# Problem 3

```{r}
patsatisfaction_data = readxl::read_excel("./data/PatSatisfaction.xlsx") %>%
  janitor::clean_names()
```

### a)

#### Create a correlation matrix

```{r}
Hmisc::rcorr(as.matrix(patsatisfaction_data))
pairs(patsatisfaction_data)
```

##### Initial Findings

* Satisfaction and age have the strong negative association. Satisfication has the moderately strong negative association with both severity and anxiety. 

* Anxiety and severity have the moderately strong positive association, we might want to check **collinearity** later. 

* Severity and age have the moderately strong positive association, which is the same as the association between anxiety and age.

### b)

##### Fit a multiple regression model and test whether there is a regression relation and test whether there is a regression relation.

Ho: beta_age = beta_severity = beta_anxiety = 0

Ha: at lease one beta is not 0

Model: satification = beta_0 + beta_age * age + beta_severity * severity + beta_anxiety * anxiety

```{r}
reg_mlr = lm(safisfaction ~ age + severity + anxiety, patsatisfaction_data)
summary(reg_mlr)
```

##### State the hypotheses, decision rule and conclusion.

Ho: beta_age = beta_severity = beta_anxiety = 0

Ha: at least one beta is not 0

If the p-value is less than 0.05, we reject Ho and conclude that at least one beta is not 0 and there is a regression relation. If not, we do not reject Ho and conclude that beta_age = beta_severity = beta_anxiety = 0 and there is not a regression relation.

Since p-value is far less than 0.05, we reject Ho and conclude that at least one beta is not 0 and there is a regression relation.

### c)

```{r}
confint(reg_mlr, level = 0.95) %>%
  knitr::kable(digits = 1)
```

* The 95% CI for beta_0 is (121.9, 195.1).

* The 95% CI for beta_age is (-1.6, -0.7).

* The 95% CI for beta_severity is (-1.4, 0.6).

* The 95% CI for beta_anxiety is (-27.8, 0.9). 

##### Interpret the coefficient and 95% CI associated with `severity`.

* The coefficient of `severity`: satisfaction will decrease by 0.442 units on average if severity increases by 1 unit adjusting age and anxiety constant.

* We are 95% confident that satisfaction will differ between -1.4 units and 0.6 units on average if severity increases by 1 unit adjusting age and anxiety constant.

### d)

##### Obtain an interval estimate for a new patient’s satisfaction when Age = 35, Severity = 42, Anxiety = 2.1. 

```{r}
input_data = data.frame(age = 35, severity = 42, anxiety = 2.1)
predict(reg_mlr, input_data, interval = "predict")
```

(beta_0 + beta_age * age + beta_severity * severity + beta_anxiety * anxiety) +- t(alpha, n - 2) * sqrt(MSE(1 + 1/n + (xh - xbar)^2 / sum((xi - xbar)^2)))

After pluging in the value, we have 95% prediction CI (50, 93).

##### Interpret

We are 95% confident that the next new satisfaction observation with age = 35, severity = 42, and anxiety = 2.1 is between 50 and 93. 

### e)

##### Test whether `anxiety` can be dropped from the regression model, given the other two covariates are retained.

For linear model:

Ho: beta_age = beta_age = beta_severity = 0

Ha: at least one beta is not 0

Model: safisfaction = beta_0 + beta_age * age + beta_severity * severity

For ANOVA model:

Ho: beta_anxiety = 0

Ha: beta_anxiety != 0

```{r}
reg_mlr_sub = lm(safisfaction ~ age + severity, patsatisfaction_data)
summary(reg_mlr_sub)

anova(reg_mlr_sub, reg_mlr)
```

##### State the hypotheses, decision rule and conclusion.

Ho: beta_anxiety = 0

Ha: beta_anxiety != 0

If the p-value is less than 0.05, we reject Ho and conclude that beta_anxiety is not 0 and we can't drop the variable anxiety from the regression model. If not, we do not reject Ho and conclude that beta_anxiety is 0 and we can drop the variable anxiety from the regression model.

Since p-value is greater than 0.05, we don't reject Ho and conclude that beta_anxiety is 0 and we can drop the variable anxiety from the regression model.
